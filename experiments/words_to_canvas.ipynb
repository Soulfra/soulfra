{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé® Words to Canvas - Build an LLM from YOUR Vocabulary\n",
        "\n",
        "**Concept:** Train a tiny LLM using ONLY your controlled vocabulary (StPetePros wordlist), then expand knowledge on-demand by fetching from Wikipedia/news.\n",
        "\n",
        "This is like **\"reverse OCR\"** - instead of image ‚Üí text, we do:\n",
        "\n",
        "```\n",
        "Your Words ‚Üí Word Embeddings ‚Üí Tiny LLM ‚Üí Generated Text ‚Üí Canvas Visualization\n",
        "                                 ‚Üì\n",
        "                  (expand vocabulary from Wikipedia when needed)\n",
        "```\n",
        "\n",
        "**What makes this unique:**\n",
        "- Starts with YOUR 263 Tampa Bay words\n",
        "- Learns relationships through embeddings\n",
        "- Expands contextually (not pre-trained on entire internet)\n",
        "- Visualizes knowledge graph on canvas\n",
        "- Pure numpy (no black boxes)\n",
        "\n",
        "**Sections:**\n",
        "1. Load your vocabulary\n",
        "2. Train word embeddings (Word2Vec-style)\n",
        "3. Build tiny transformer LLM\n",
        "4. Generate text from prompts\n",
        "5. Expand vocabulary from Wikipedia\n",
        "6. Visualize knowledge graph on canvas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup imports\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add core directory to path\n",
        "sys.path.insert(0, os.path.abspath('../core'))\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Import our custom modules\n",
        "from word_embeddings import WordEmbeddings, build_vocabulary_from_wordlist, generate_training_pairs\n",
        "from vocabulary_expander import VocabularyExpander\n",
        "from tiny_llm import TinyLLM\n",
        "from canvas_visualizer import CanvasVisualizer\n",
        "\n",
        "print(\"‚úÖ Imports loaded!\")\n",
        "print(\"üì¶ Modules available:\")\n",
        "print(\"   - WordEmbeddings (Word2Vec-style)\")\n",
        "print(\"   - VocabularyExpander (Wikipedia/dictionary)\")\n",
        "print(\"   - TinyLLM (Transformer from scratch)\")\n",
        "print(\"   - CanvasVisualizer (Knowledge graph)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Your Vocabulary\n",
        "\n",
        "Start with your 263 StPetePros words (Tampa Bay themed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load base vocabulary from wordlist\n",
        "wordlist_path = '../stpetepros-wordlist.txt'\n",
        "\n",
        "words, word_to_idx, idx_to_word = build_vocabulary_from_wordlist(wordlist_path)\n",
        "\n",
        "print(f\"\\nüìö Your Vocabulary:\")\n",
        "print(f\"   Total words: {len(words)}\")\n",
        "print(f\"\\n   Sample words:\")\n",
        "for i, word in enumerate(words[:20]):\n",
        "    print(f\"      {i}: {word}\")\n",
        "\n",
        "print(f\"\\n   ... and {len(words) - 20} more!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Train Word Embeddings\n",
        "\n",
        "Learn vector representations where similar words have similar vectors.\n",
        "\n",
        "**Algorithm:** Word2Vec Skip-gram\n",
        "- For each word, predict surrounding context words\n",
        "- Train 2-layer neural network\n",
        "- Extract hidden layer as embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate training pairs (word, context) from vocabulary sequence\n",
        "training_pairs_idx = generate_training_pairs(\n",
        "    list(range(len(words))),\n",
        "    window_size=3  # Consider 3 words on each side as context\n",
        ")\n",
        "\n",
        "print(f\"\\nüîó Training Pairs Generated:\")\n",
        "print(f\"   Total pairs: {len(training_pairs_idx)}\")\n",
        "print(f\"\\n   Sample pairs (word ‚Üí context):\")\n",
        "for i, (word_idx, context_idx) in enumerate(training_pairs_idx[:10]):\n",
        "    print(f\"      {idx_to_word[word_idx]} ‚Üí {idx_to_word[context_idx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize word embeddings\n",
        "embeddings = WordEmbeddings(\n",
        "    vocab_size=len(words),\n",
        "    embedding_dim=50,  # 50-dimensional vectors\n",
        "    learning_rate=0.1\n",
        ")\n",
        "\n",
        "# Train embeddings\n",
        "embeddings.train(\n",
        "    training_pairs_idx,\n",
        "    epochs=100,  # More epochs = better embeddings (but slower)\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Embeddings trained!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test word similarity\n",
        "print(\"\\nüîç Word Similarities:\")\n",
        "\n",
        "test_words = ['plumber', 'tampa', 'repair', 'service', 'professional']\n",
        "\n",
        "for word in test_words:\n",
        "    if word not in word_to_idx:\n",
        "        print(f\"   '{word}' not in vocabulary\")\n",
        "        continue\n",
        "\n",
        "    word_idx = word_to_idx[word]\n",
        "    similar = embeddings.most_similar(word_idx, word_to_idx, idx_to_word, top_k=5)\n",
        "\n",
        "    print(f\"\\n   '{word}' is similar to:\")\n",
        "    for sim_word, score in similar:\n",
        "        print(f\"      {sim_word}: {score:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Build Tiny Transformer LLM\n",
        "\n",
        "Create a minimal GPT-style transformer:\n",
        "- Self-attention mechanism\n",
        "- Feed-forward layers\n",
        "- Positional encodings\n",
        "- Next-token prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Tiny LLM\n",
        "llm = TinyLLM(\n",
        "    vocab_size=len(words),\n",
        "    embedding_dim=50,  # Match embeddings dimension\n",
        "    max_seq_len=20,  # Maximum sequence length\n",
        "    learning_rate=0.01\n",
        ")\n",
        "\n",
        "# Load pre-trained word embeddings\n",
        "llm.load_embeddings(embeddings.get_all_embeddings())\n",
        "\n",
        "print(\"\\n‚úÖ Tiny LLM initialized with pre-trained embeddings!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Generate Text\n",
        "\n",
        "Use the LLM to generate text from prompts using YOUR vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test text generation\n",
        "print(\"\\nüé® Generating Text from Prompts:\\n\")\n",
        "\n",
        "prompts = [\n",
        "    ['tampa', 'bay', 'plumber'],\n",
        "    ['reliable', 'professional', 'service'],\n",
        "    ['repair', 'fix', 'install']\n",
        "]\n",
        "\n",
        "for prompt_words in prompts:\n",
        "    # Convert words to indices\n",
        "    prompt_ids = [word_to_idx[w] for w in prompt_words if w in word_to_idx]\n",
        "\n",
        "    if not prompt_ids:\n",
        "        print(f\"   Prompt words not in vocabulary: {prompt_words}\")\n",
        "        continue\n",
        "\n",
        "    # Generate continuation\n",
        "    generated_ids = llm.generate(\n",
        "        prompt_ids=np.array(prompt_ids),\n",
        "        max_new_tokens=5,\n",
        "        temperature=0.8,  # Higher = more random\n",
        "        idx_to_word=idx_to_word\n",
        "    )\n",
        "\n",
        "    # Convert back to words\n",
        "    generated_words = [idx_to_word.get(i, '<?>')  for i in generated_ids]\n",
        "    print(f\"   Prompt: {' '.join(prompt_words)}\")\n",
        "    print(f\"   Generated: {' '.join(generated_words)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Expand Vocabulary from Wikipedia\n",
        "\n",
        "When you encounter unknown words, fetch definitions on-demand.\n",
        "\n",
        "This is the **\"reverse OCR\"** magic - expand knowledge contextually, not upfront!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize vocabulary expander\n",
        "expander = VocabularyExpander(base_vocab_path='../stpetepros-wordlist.txt')\n",
        "\n",
        "# Words to expand (not in your base vocabulary)\n",
        "expand_words = [\n",
        "    'database',\n",
        "    'cryptocurrency',\n",
        "    'blockchain',\n",
        "    'neural',\n",
        "    'algorithm'\n",
        "]\n",
        "\n",
        "print(\"\\nüåê Expanding Vocabulary from Wikipedia:\\n\")\n",
        "\n",
        "# Expand words\n",
        "results = expander.batch_expand(expand_words, sources=['wikipedia', 'builtin'])\n",
        "\n",
        "# Show results\n",
        "for word, definition in results.items():\n",
        "    if definition:\n",
        "        print(f\"\\n‚úÖ {word}:\")\n",
        "        print(f\"   {definition['definition'][:150]}...\")\n",
        "        print(f\"   Source: {definition['source']}\")\n",
        "\n",
        "        # Show related words from your base vocabulary\n",
        "        related = expander.get_related_words(word)\n",
        "        if related:\n",
        "            print(f\"   Related to: {', '.join(related[:3])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show expansion statistics\n",
        "stats = expander.get_expansion_stats()\n",
        "\n",
        "print(\"\\nüìä Vocabulary Statistics:\")\n",
        "print(f\"   Base vocabulary: {stats['base_vocab_size']} words\")\n",
        "print(f\"   Expanded vocabulary: {stats['expanded_vocab_size']} words\")\n",
        "print(f\"   Total vocabulary: {stats['total_vocab_size']} words\")\n",
        "print(f\"   Expansion rate: {stats['expanded_vocab_size'] / stats['base_vocab_size'] * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Visualize Knowledge Graph on Canvas\n",
        "\n",
        "Render your vocabulary + expansions as an interactive knowledge graph.\n",
        "\n",
        "This is the **\"canvas\"** part - visual representation of your LLM's knowledge!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build knowledge graph from expanded vocabulary\n",
        "graph = expander.build_knowledge_graph()\n",
        "\n",
        "print(\"\\nüï∏Ô∏è Knowledge Graph Built:\")\n",
        "print(f\"   Nodes: {len(graph['nodes'])}\")\n",
        "print(f\"   Edges: {len(graph['edges'])}\")\n",
        "\n",
        "# Show sample nodes\n",
        "print(\"\\n   Sample nodes:\")\n",
        "for node in graph['nodes'][:10]:\n",
        "    node_type = node.get('type', 'unknown')\n",
        "    print(f\"      {node['label']} ({node_type})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizer\n",
        "viz = CanvasVisualizer(width=800, height=600)\n",
        "\n",
        "# Compute force-directed layout\n",
        "positions = viz.layout_force_directed(\n",
        "    nodes=graph['nodes'],\n",
        "    edges=graph['edges'],\n",
        "    iterations=50\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Layout computed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "output_dir = Path('../data/words_to_canvas')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Render visualizations\n",
        "print(\"\\nüé® Rendering Visualizations:\\n\")\n",
        "\n",
        "# 1. SVG (static vector graphics)\n",
        "svg_path = output_dir / 'knowledge_graph.svg'\n",
        "viz.render_svg(graph['nodes'], graph['edges'], positions, str(svg_path))\n",
        "\n",
        "# 2. Interactive HTML\n",
        "html_path = output_dir / 'knowledge_graph.html'\n",
        "viz.render_html_interactive(graph['nodes'], graph['edges'], positions, str(html_path))\n",
        "\n",
        "# 3. JSON export\n",
        "json_path = output_dir / 'knowledge_graph.json'\n",
        "viz.export_json(graph['nodes'], graph['edges'], positions, str(json_path))\n",
        "\n",
        "print(f\"\\n‚úÖ All visualizations saved to: {output_dir}\")\n",
        "print(f\"\\n   üåê Open {html_path} in your browser to explore!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show ASCII version (for terminal/notebook)\n",
        "ascii_graph = viz.render_ascii(graph['nodes'], graph['edges'], positions)\n",
        "print(ascii_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Save Everything\n",
        "\n",
        "Persist your trained models and expanded vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save word embeddings\n",
        "embeddings_path = output_dir / 'word_embeddings.json'\n",
        "embeddings.save(str(embeddings_path), word_to_idx, idx_to_word)\n",
        "\n",
        "# Save LLM\n",
        "llm_path = output_dir / 'tiny_llm.json'\n",
        "llm.save(str(llm_path))\n",
        "\n",
        "# Save expanded vocabulary\n",
        "vocab_path = output_dir / 'expanded_vocabulary.json'\n",
        "expander.save_expanded_vocab(str(vocab_path))\n",
        "\n",
        "print(\"\\nüíæ All models saved!\")\n",
        "print(f\"   Embeddings: {embeddings_path}\")\n",
        "print(f\"   LLM: {llm_path}\")\n",
        "print(f\"   Vocabulary: {vocab_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: What We Built\n",
        "\n",
        "üéâ **Congratulations!** You just built:\n",
        "\n",
        "1. ‚úÖ **Word Embeddings** - Word2Vec-style vectors from YOUR vocabulary\n",
        "2. ‚úÖ **Vocabulary Expander** - On-demand knowledge from Wikipedia\n",
        "3. ‚úÖ **Tiny LLM** - Transformer from scratch (pure numpy)\n",
        "4. ‚úÖ **Text Generator** - Generate Tampa Bay business descriptions\n",
        "5. ‚úÖ **Knowledge Graph** - Visualize relationships on canvas\n",
        "\n",
        "**This is \"reverse OCR\":**\n",
        "- Instead of: Image ‚Üí Text\n",
        "- You built: Words ‚Üí LLM ‚Üí Canvas Visualization\n",
        "\n",
        "**Key innovations:**\n",
        "- Controlled vocabulary (your 263 words)\n",
        "- Contextual expansion (Wikipedia on-demand)\n",
        "- Transparent (no black boxes)\n",
        "- Visual (knowledge graph)\n",
        "\n",
        "**Next steps:**\n",
        "- Train on real Tampa Bay business data\n",
        "- Expand to more sources (news, dictionary, Python docs)\n",
        "- Add more LLM layers (multi-head attention)\n",
        "- Fine-tune for specific domains\n",
        "\n",
        "**Open the HTML visualization to explore your knowledge graph!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
